{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi\n",
    "#### Using the Full Test Data @ 5% of given corpus\n",
    "##### Note: The plain vanilla Viterbi algorithm takes 10-12 min to run on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(tag_seq, test_seq):\n",
    "    check = [i for i, j in zip(tag_seq, test_seq) if i == j]  \n",
    "    return(len(check)/len(tag_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view of first few tagged sentences\n",
    "print(nltk_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(1234)\n",
    "train_set, validn_set = train_test_split(nltk_data,test_size=0.05)\n",
    "print(len(train_set))\n",
    "print(len(validn_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_set[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validn_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of unique tags from the training data \n",
    "tag_set = set([pair[1] for pair in train_tagged_words])\n",
    "\n",
    "# add a custom unknown tag UNK to cover situations where probability is zero.\n",
    "#tag_set.add('UNK')\n",
    "print(tag_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all occurrences of tags in training data\n",
    "train_tags = [pair[1] for pair in train_tagged_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "len(tokens)\n",
    "V = set(tokens)\n",
    "\n",
    "vocab_count = len(V)\n",
    "vocab_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Define Function to Calculate Emission Probability  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given word & tag, determine the emission probability based on train set\n",
    "def word_emission_prob(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag/count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test examples\n",
    "\n",
    "word='offer'\n",
    "print(\"emission probability of the word\", word,\"given a few tags below:\")\n",
    "t1=time.time()\n",
    "print(\"ADJ:\", word_emission_prob(word, 'ADJ'))\n",
    "t2=time.time()\n",
    "print(t2-t1,'secs.')\n",
    "\n",
    "t1=time.time()\n",
    "print(\"VERB:\", word_emission_prob(word, 'VERB'))\n",
    "t2=time.time()\n",
    "print(t2-t1,'secs.')\n",
    "\n",
    "t1=time.time()\n",
    "print(\"NOUN:\", word_emission_prob(word, 'NOUN'))\n",
    "t2=time.time()\n",
    "print(t2-t1,'secs.')\n",
    "\n",
    "print(\"PRON:\", word_emission_prob(word, 'PRON'))\n",
    "\n",
    "\n",
    "word='win'\n",
    "print(\"emission probability of the word\", word,\"given a few tags below:\")\n",
    "print(\"ADJ:\", word_emission_prob(word, 'ADJ'))\n",
    "print(\"VERB:\", word_emission_prob(word, 'VERB'))\n",
    "print(\"NOUN:\", word_emission_prob(word, 'NOUN'))\n",
    "print(\"PRON:\", word_emission_prob(word, 'PRON'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Set up Transition Probabilities (of tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to compute transition probability of tag1 to tag2 \n",
    "\n",
    "def transition_prob(t1, t2, tags=train_tags):\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t1_to_t2 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t1_to_t2 += 1\n",
    "    return (count_t1_to_t2/count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all possible transition probabilities\n",
    "\n",
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tag_set), len(tag_set)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tag_set)):\n",
    "    for j, t2 in enumerate(list(tag_set)): \n",
    "        tags_matrix[i, j] = transition_prob(t1,t2)\n",
    "#tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tag_set), index=list(tag_set))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with examples\n",
    "\n",
    "t1=\"ADJ\"\n",
    "t2=\"NOUN\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])\n",
    "\n",
    "t1=\".\"\n",
    "t2=\"DET\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])\n",
    "\n",
    "t1=\".\"\n",
    "t2=\"NOUN\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])\n",
    "\n",
    "t1=\"ADV\"\n",
    "t2=\"VERB\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])\n",
    "\n",
    "t1=\"VERB\"\n",
    "t2=\"NOUN\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])\n",
    "\n",
    "t1=\"NOUN\"\n",
    "t2=\".\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])\n",
    "\n",
    "t2=\"NOUN\"\n",
    "t1=\"NUM\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])\n",
    "\n",
    "t1=\"CONJ\"\n",
    "t2=\"NOUN\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])\n",
    "\n",
    "t2=\"CONJ\"\n",
    "t1=\"NOUN\"\n",
    "print(\"Transition probability of\", t1, \"to\", t2, \":\", tags_df.loc[t1,t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup words to test algo \n",
    "\n",
    "validn_run_words = [tup[0] for sent in validn_set for tup in sent]\n",
    "validn_run_base = [tup for sent in validn_set for tup in sent]\n",
    "len(validn_run_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Define \"vanilla\" Viterbi Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    print('tagging, please wait. this could take several seconds/minutes ...\\n')\n",
    "    state = []\n",
    "    tot_words = len(words)\n",
    "    words_tagged = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "   \n",
    "    T = list(tag_set)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "            \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_emission_prob(words[key], tag) \n",
    "\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "        \n",
    "        \n",
    "        ## print periodic (every 50 words tagged) status message\n",
    "        words_tagged += 1\n",
    "        if (words_tagged % 50 == 0):\n",
    "            end_time = time.time()\n",
    "            diff = end_time - start_time\n",
    "            print(words_tagged, 'words done (', int((words_tagged/tot_words)*100),'%)', int(diff), 'secs ...', end=\" \")\n",
    "            \n",
    "        \n",
    "    print('\\n\\n',words_tagged,'words tagged! thanks for your patience.')\n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run the plain, vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(validn_run_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -----------------------------------------------------------------------\n",
    "##### Save the tagged sequence & validation run base into files to save time if needed to re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tagged_seq)\n",
    "with open(\"tagged_seq_full.txt\", \"w\") as output:\n",
    "    output.write(str(tagged_seq))\n",
    "    \n",
    "with open(\"validn_run_base_full.txt\", \"w\") as output:\n",
    "    output.write(str(validn_run_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validn_run_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute this if resuming after running Viterbi algo on validation data set.\n",
    "##### Load up tagged sequence from a file saved in previous run(s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import ast\n",
    "with open('tagged_seq_full.txt', 'r') as f:\n",
    "    tagged_seq = ast.literal_eval(f.read())\n",
    "\n",
    "with open('validn_run_base_full.txt', 'r') as f:\n",
    "    validn_run_base = ast.literal_eval(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(validn_run_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcuate accuracy of the vanilla viterbi algorithm\n",
    "vanilla_viterbi_accuracy = check_accuracy(tagged_seq, validn_run_base)\n",
    "print(\"Accuracy of Vanilla Viteri algorithm:\", vanilla_viterbi_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect incorrectly tagged cases\n",
    "incorrect_tagged_cases = [[tagged_seq[i-1],j] for i, j in enumerate(zip(tagged_seq, validn_run_base)) if j[0]!=j[1]]\n",
    "print('No of Incorrectly tagged cases:', len(incorrect_tagged_cases))\n",
    "print(incorrect_tagged_cases[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Test_sentences.txt', 'r') as f:\n",
    "    test_sents = (f.readlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents\n",
    "test_sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Algo on unknown sentences\n",
    "\n",
    "## Testing\n",
    "tagged_seq_new_words = []\n",
    "for sent in test_sents:\n",
    "    words = word_tokenize(sent)\n",
    "\n",
    "    start = time.time()\n",
    "    tagged_seq_new_words.append(Viterbi(words))\n",
    "    end = time.time()\n",
    "    difference = end-start\n",
    "    \n",
    "tagged_seq_new_words    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modfication Technique I :  Incorporate regex based tagger into Viterbi algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "(r'.+-.+ed$', 'ADJ'),           # to handle adjectives such as best-selling,\n",
    "(r'.*ed$', 'VERB'),               # past tense\n",
    "(r'.+-.+ing$', 'ADJ'),           # to handle adjectives such as best-selling,\n",
    "(r'.+ing$', 'VERB'),               # past tense\n",
    "(r'.*ly$', 'ADV'),                # adverb\n",
    "(r'.+est$','ADJ'),                # superlatives \n",
    "(r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)   \n",
    "         \n",
    "t0 = nltk.DefaultTagger('NOUN')\n",
    "regex_tagger = nltk.RegexpTagger(patterns, backoff=t0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic modified to include regexp pattern tagging\n",
    "#\n",
    "\n",
    "def ViterbiMod1(words, train_bag = train_tagged_words):\n",
    "    print('tagging, please wait\\n')\n",
    "    state = []\n",
    "    tot_words = len(words)\n",
    "    words_tagged = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    T = list(tag_set)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "            \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_emission_prob(words[key], tag) \n",
    "\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "        # if emission probability is ZERO, invoke the regexp-tagger with backoff \n",
    "        if (pmax == 0):\n",
    "            state_max = regex_tagger.tag([word])[0][1]\n",
    "            print('ZERO EMISSION ALT TAG:', state_max, 'for word:', word)\n",
    "            \n",
    "        state.append(state_max)\n",
    "        \n",
    "        words_tagged += 1\n",
    "        \n",
    "        #print periodic progress status: for every 50 words processed.\n",
    "        if ((words_tagged % 50) == 0):\n",
    "            end_time = time.time()\n",
    "            diff = end_time - start_time\n",
    "            print(words_tagged, 'words done (', int((words_tagged/tot_words)*100),'%)', int(diff), 'secs ...', end=\" \")\n",
    "            \n",
    "\n",
    "    print('\\n\\n',words_tagged,'words tagged! thanks for your patience.')\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the Viterbi Mod-1 tagger\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq_mod1 = ViterbiMod1(validn_run_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy of Viterbi Mod-1 algo\n",
    "mod1_viterbi_accuracy = check_accuracy(tagged_seq_mod1, validn_run_base)\n",
    "print(\"Accuracy of Viterbi Mod-1 tagger:\", mod1_viterbi_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect incorrectly tagged cases\n",
    "incorrect_tagged_cases_mod1 = [[tagged_seq_mod1[i-1],j] for i, j in enumerate(zip(tagged_seq_mod1, validn_run_base)) if j[0]!=j[1]]\n",
    "print('No of Incorrectly tagged cases:', len(incorrect_tagged_cases_mod1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases_mod1[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Mod-1  tagger on unknown sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "tagged_seq_mod1_new_words = []\n",
    "for sent in test_sents:\n",
    "    words = word_tokenize(sent)\n",
    "\n",
    "    start = time.time()\n",
    "    tagged_seq_mod1_new_words.append(ViterbiMod1(words))\n",
    "    end = time.time()\n",
    "    difference = end-start\n",
    "    \n",
    "tagged_seq_mod1_new_words    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Viterbi Mod-1 tagger has done a better job with unknown words\n",
    "##### e.g. words like \"Google\", \"Android\" etc. that were tagged as CONJ by the vanilla Viterbi algo are now tagged correctly as NOUN. Also, numbers like 2011 are now tagged correctly as NUM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Modification Technique II : Add Bigram tagger to Viterbi Mod-1 algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bigram tagger\n",
    "\n",
    "## Testing\n",
    "#tagged_seq_bigram_words = []\n",
    "#for sent in test_sents:\n",
    "#    words = word_tokenize(sent)\n",
    "#\n",
    "#    start = time.time()\n",
    "#    tagged_seq_bigram_words.append(bi_tagger.tag(words))\n",
    "#    end = time.time()\n",
    "#    difference = end-start\n",
    "    \n",
    "    \n",
    "# Evaluate accuracy of Bigram algo\n",
    "#tagged_seq_bigram = bi_tagger.tag(validn_run_words)\n",
    "#bigram_accuracy = check_accuracy(tagged_seq_bigram, validn_run_base)\n",
    "#print(\"Accuracy of Bigram tagger:\", bigram_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NOUN')\n",
    "t1 = nltk.RegexpTagger(patterns, backoff=t0)\n",
    "t2 = nltk.UnigramTagger(train_set, backoff=t1)\n",
    "reg_bi_tagger = nltk.BigramTagger(train_set, backoff=t1)\n",
    "\n",
    "t0 = nltk.DefaultTagger('NOUN')\n",
    "t1 = nltk.UnigramTagger(train_set, backoff=t0)\n",
    "bi_tagger = nltk.BigramTagger(train_set, backoff=t1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'DET', 'X', 'NOUN', 'ADP', 'VERB', 'PRT', 'NUM', 'ADJ', '.', 'PRON', 'CONJ', 'ADV'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word='Name'\n",
    "print(reg_bi_tagger.tag([word]))\n",
    "print(bi_tagger.tag([word]))\n",
    "\n",
    "for tag in tag_set:\n",
    "    print(tag, ':', word_emission_prob(word,tag))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic modified to include bigram tagging (on top of regex tagger in Mod-1)\n",
    "#\n",
    "\n",
    "def ViterbiMod2(words, train_bag = train_tagged_words):\n",
    "    t0 = nltk.DefaultTagger('NOUN')\n",
    "    t1 = nltk.UnigramTagger(train_set, backoff=t0)\n",
    "    bi_tagger = nltk.BigramTagger(train_set, backoff=t1)\n",
    "    \n",
    "    print('tagging, please wait\\n')\n",
    "    state = []\n",
    "    tot_words = len(words)\n",
    "    words_tagged = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    T = list(tag_set)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "            \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            #emission_p = word_emission_laplace(words[key], tag) \n",
    "            emission_p = word_emission_prob(words[key], tag) \n",
    "\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "        # if emission probability is ZERO, invoke the bigram-tagger with backoff \n",
    "        if (pmax == 0):\n",
    "            state_max = bi_tagger.tag([word])[0][1]\n",
    "            print('ZERO EMISSION ALT TAG:', state_max, 'for word:', word)\n",
    "            \n",
    "        state.append(state_max)\n",
    "        \n",
    "        words_tagged += 1\n",
    "        \n",
    "        #print periodic progress status: for every 50 words processed.\n",
    "        if ((words_tagged % 50) == 0):\n",
    "            end_time = time.time()\n",
    "            diff = end_time - start_time\n",
    "            print(words_tagged, 'words done (', int((words_tagged/tot_words)*100),'%)', int(diff), 'secs ...', end=\" \")\n",
    "            \n",
    "\n",
    "    print('\\n\\n',words_tagged,'words tagged! thanks for your patience.')\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the Viterbi Mod-2 tagger\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq_mod2 = ViterbiMod2(validn_run_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy of Viterbi Mod-2 algo\n",
    "mod2_viterbi_accuracy = check_accuracy(tagged_seq_mod2, validn_run_base)\n",
    "print(\"Accuracy of Viterbi Mod-2 tagger:\", mod2_viterbi_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect incorrectly tagged cases\n",
    "incorrect_tagged_cases_mod2 = [[tagged_seq_mod2[i-1],j] for i, j in enumerate(zip(tagged_seq_mod2, validn_run_base)) if j[0]!=j[1]]\n",
    "print('No of Incorrectly tagged cases:', len(incorrect_tagged_cases_mod2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases_mod2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "tagged_seq_mod2_new_words = []\n",
    "for sent in test_sents:\n",
    "    words = word_tokenize(sent)\n",
    "\n",
    "    start = time.time()\n",
    "    tagged_seq_mod2_new_words.append(ViterbiMod2(words))\n",
    "    end = time.time()\n",
    "    difference = end-start\n",
    "    \n",
    "tagged_seq_mod2_new_words    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vanilla Viterbi Accuracy:', vanilla_viterbi_accuracy)\n",
    "print('Modified-1 Viterbi Accuracy:', mod1_viterbi_accuracy)\n",
    "print('Modified-2 Viterbi Accuracy:', mod2_viterbi_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cases tagged incorrectly by original POS tagger - vanilla viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df of all incorrect cases from original POS tagger \n",
    "#\n",
    "orig_incorrect_pairs = [j[0] for i,j in incorrect_tagged_cases]\n",
    "orig_incorrect_case_words = [pair[0] for pair in orig_incorrect_pairs]\n",
    "orig_incorrect_case_tags = [pair[1] for pair in orig_incorrect_pairs]\n",
    "orig_incorrect_case_tags\n",
    "#in_words = [pair[0] for pair in tagged_seq_mod1]\n",
    "\n",
    "incorrect_df = pd.DataFrame( columns = ['tag'], index=orig_incorrect_case_words)\n",
    "incorrect_df.tag = orig_incorrect_case_tags\n",
    "#incorrect_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cases tagged correctly by original Mod-1 Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df of all Mod-1 word tag pairs\n",
    "#\n",
    "mod1_words = [pair[0] for pair in tagged_seq_mod1]\n",
    "mod1_tags = [pair[1] for pair in tagged_seq_mod1]\n",
    "mod1_df = pd.DataFrame( columns = ['tag'], index=mod1_words)\n",
    "mod1_df.tag = mod1_tags\n",
    "#mod1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cases tagged correctly by original Mod-2 Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df of all Mod-2 word tag pairs\n",
    "#\n",
    "mod2_words = [pair[0] for pair in tagged_seq_mod2]\n",
    "mod2_tags = [pair[1] for pair in tagged_seq_mod2]\n",
    "mod2_df = pd.DataFrame( columns = ['tag'], index=mod2_words)\n",
    "mod2_df.tag = mod2_tags\n",
    "#mod2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tags from the mod1 Viterbi that are correctly tagged now v/s vanilla Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#word='struggled'\n",
    "#print('incorrect tag for word', word, ':', incorrect_df.loc[word].tag, \n",
    "# 'v/s correct tag in mod-1:', mod1_df.loc[word].tag)\n",
    "\n",
    "#word='534'\n",
    "#print('incorrect tag for word', word, ':', incorrect_df.loc[word].tag, \n",
    "# 'v/s correct tag in mod-1:', mod1_df.loc[word].tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "incorrect tag for word *struggled* : DET v/s correct tag in Viterbi Mod-1: VERB\n",
    "\n",
    "incorrect tag for word *534* : DET v/s correct tag in Viterbi Mod-1: NUM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tags from the mod2 Viterbi that are correctly tagged now v/s vanilla Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#word='redemption'\n",
    "#print('incorrect tag for word', word, ':', incorrect_df.loc[word].tag, \n",
    "# 'v/s correct tag in mod-2:', mod2_df.loc[word].tag)\n",
    "\n",
    "#word='534'\n",
    "#print('incorrect tag for word', word, ':', incorrect_df.loc[word].tag, \n",
    " 'v/s correct tag in mod-2:', mod2_df.loc[word].tag)\n",
    "\n",
    "#word='examined'\n",
    "#print('incorrect tag for word', word, ':', incorrect_df.loc[word].tag, \n",
    "# 'v/s correct tag in mod-2:', mod2_df.loc[word].tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "incorrect tag for word *redemption*: NOUN v/s correct tag in mod-2: NOUN\n",
    "\n",
    "incorrect tag for word *534* : DET v/s correct tag in mod-2: NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
