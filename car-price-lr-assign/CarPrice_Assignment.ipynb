{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "## Car Price Case Study\n",
    "\n",
    "#### Problem Statement:\n",
    "\n",
    "This assignment submission attempts to build a multiple linear regression model for the prediction of car prices. \n",
    "\n",
    "A Chinese automobile company __Geely Auto__ aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts. \n",
    "\n",
    "They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. \n",
    "The company wants to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. \n",
    "\n",
    "The company wants to know:\n",
    "- Which variables are significant in predicting the price of a car\n",
    "- How well those variables describe the price of a car\n",
    "\n",
    "Based on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the Americal market. \n",
    "\n",
    "__Business Goal__ \n",
    "\n",
    "This notebook will model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Reading and Understanding the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defining a function for calculating VIFs for passed in DF\n",
    "def build_VIF(X):\n",
    "    vif = pd.DataFrame()\n",
    "    \n",
    "    vif['Features'] = X.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'], 2)\n",
    "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "    print(vif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"CarPrice_Assignment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Car Company column by extracting it from the CarName column and drop the CarName column now\n",
    "cars['carco'] = cars['CarName'].str.split(n=1, expand=True)[0]\n",
    "cars.drop(columns=['CarName'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the head of the dataset\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the various aspects of the cars dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cars.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Visualising and Understanding Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising Numeric Variables\n",
    "Pairplot of all the numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.pairplot(cars, height=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the pairplot above \n",
    "\n",
    "1. *wheelbase* seems to have a discernible pattern of relationship with *price*\n",
    "2. *carwidth*, *carheight* & *curbweight* seem to have a discernible pattern of positive correlation with *price*.\n",
    "    These 3 variable also seem to be strongly correlated amongst themselves.\n",
    "3. *boreratio* & *stroke* seem to have a discernible pattern of positive correlation with *price*.\n",
    "4. *citympg* & *highwaympg* seem to have a discernible negative correlation with *price* and a positive correlation between themselves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising Categorical Variables\n",
    "\n",
    "Boxplot for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.subplot(4,3,1)\n",
    "sns.boxplot(x = 'carco', y = 'price', data = cars)\n",
    "plt.subplot(4,3,2)\n",
    "sns.boxplot(x = 'fueltype', y = 'price', data = cars)\n",
    "plt.subplot(4,3,3)\n",
    "sns.boxplot(x = 'aspiration', y = 'price', data = cars)\n",
    "plt.subplot(4,3,4)\n",
    "sns.boxplot(x = 'doornumber', y = 'price', data = cars)\n",
    "plt.subplot(4,3,5)\n",
    "sns.boxplot(x = 'carbody', y = 'price', data = cars)\n",
    "plt.subplot(4,3,6)\n",
    "sns.boxplot(x = 'drivewheel', y = 'price', data = cars)\n",
    "plt.subplot(4,3,7)\n",
    "sns.boxplot(x = 'enginelocation', y = 'price', data = cars)\n",
    "plt.subplot(4,3,8)\n",
    "sns.boxplot(x = 'enginetype', y = 'price', data = cars)\n",
    "plt.subplot(4,3,9)\n",
    "sns.boxplot(x = 'cylindernumber', y = 'price', data = cars)\n",
    "plt.subplot(4,3,10)\n",
    "sns.boxplot(x = 'fuelsystem', y = 'price', data = cars)\n",
    "plt.subplot(4,3,11)\n",
    "sns.boxplot(x = 'symboling', y = 'price', data = cars)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cars.carco.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Cleansing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Data Cleansing\n",
    "#\n",
    "\n",
    "# Car names have misspelt names\n",
    "#\n",
    "\n",
    "names_conv_dict = {\"carco\": \n",
    "                  {\"toyouta\": \"toyota\", \\\n",
    "                   \"vw\": \"volkswagen\", \"maxda\":\"mazda\", \"porcshce\":\"porsche\", \"vokswagen\":\"volkswagen\" }\n",
    "                  }\n",
    "cars.replace(names_conv_dict, inplace=True)\n",
    "cars.carco.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Dropping insignificant columns\n",
    "#\n",
    "\n",
    "# From the box plot above of category variales, it appears that both *fueltype* and \"doornumber\" seem to be\n",
    "# neutral to the impact on price. Hence dropping them.\n",
    "#\n",
    "cars.drop(columns=['fueltype','doornumber', 'car_ID'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Convert category variables to dummy variables\n",
    "#\n",
    "\n",
    "# Convert doornumber & cylindernumber\n",
    "nums_conv_dict = {\"cylindernumber\": {\"four\": 4, \"six\": 6, \"five\": 5, \"eight\": 8,\\\n",
    "                                     \"two\": 2, \"twelve\": 12, \"three\":3 }\n",
    "                  }\n",
    "\n",
    "cars.replace(nums_conv_dict, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing cylindernumber as boxplot after conversion for better readability.\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(x = 'cylindernumber', y = 'price', data = cars)\n",
    "#plt.subplot(4,3,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars.loc[cars.cylindernumber<=3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are only a few rows (5 out of 143) with cylindernumber 2 or 3. Barring these, there seem to be a highly positive correlation with price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get dummies for car company names\n",
    "#carco = pd.get_dummies(cars['carco'])\n",
    "carco = pd.get_dummies(cars['carco'], drop_first=True)\n",
    "carco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.concat([cars, carco], axis=1)\n",
    "cars.drop(columns=['carco'], inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp = pd.get_dummies(cars['aspiration'],drop_first=True)\n",
    "\n",
    "cars = pd.concat([cars, asp], axis=1)\n",
    "cars.drop(columns=['aspiration'], inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for carbody\n",
    "carbody = pd.get_dummies(cars['carbody'], drop_first=True)\n",
    "\n",
    "cars = pd.concat([cars, carbody], axis=1)\n",
    "cars.drop(columns=['carbody'], inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get dummies for enginelocation\n",
    "eloc = pd.get_dummies(cars['enginelocation'], drop_first=True)\n",
    "cars = pd.concat([cars, eloc], axis=1)\n",
    "cars.drop(columns=['enginelocation'], inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert engine type\n",
    "\n",
    "#\n",
    "# First, let's treat all \"ohc\" type engines the same\n",
    "#\n",
    "etype_conv_dict =  {\"enginetype\": {\"ohcf\":\"ohc\", \"ohcv\":\"ohc\", \"dohc\":\"ohc\", \"dohcv\":\"ohc\"}}\n",
    "cars.replace(etype_conv_dict, inplace=True)\n",
    "cars.enginetype.head(200)\n",
    "\n",
    "# now get dummies for enginetype\n",
    "etype = pd.get_dummies(cars['enginetype'],drop_first=True)\n",
    "etype.head()\n",
    "\n",
    "cars = pd.concat([cars, etype], axis=1)\n",
    "cars.drop(columns=['enginetype'], inplace=True)\n",
    "cars.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get dummies for drivewheel \n",
    "drwheel = pd.get_dummies(cars['drivewheel'],drop_first=True)\n",
    "drwheel.head()\n",
    "\n",
    "cars = pd.concat([cars, drwheel], axis=1)\n",
    "cars.drop(columns=['drivewheel'], inplace=True)\n",
    "cars.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now get dummies for fuelsystem \n",
    "fsys = pd.get_dummies(cars['fuelsystem'],drop_first=True)\n",
    "fsys.head()\n",
    "\n",
    "cars = pd.concat([cars, fsys], axis=1)\n",
    "cars.drop(columns=['fuelsystem'], inplace=True)\n",
    "cars.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Splitting the Data into Training and Testing Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify this so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "cars_train, cars_test = train_test_split(cars, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling the Features \n",
    "\n",
    "Using *Min-Max scaling* method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply scaler() to relevant columns \n",
    "#num_vars = ['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight', 'enginesize', 'horsepower', \\\n",
    "#            'peakrpm', 'citympg', 'highwaympg', 'price', 'compressionratio','symboling', 'cylindernumber' \\\n",
    "#            ]\n",
    "num_vars = cars_train.columns\n",
    "\n",
    "cars_train[num_vars] = scaler.fit_transform(cars_train[num_vars])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing into X and Y sets for the model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = cars_train.pop('price')\n",
    "X_train = cars_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Building a linear model using RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RFE and LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running RFE with the output number of the variable equal to 10 since,\n",
    "# based on the heatmap above, there seem to be 10 variables that have strong correlation with price.\n",
    "#\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(lm, 10)             # running RFE\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Build Model to get stats values based on the top 10 variables from RFE process above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign all the feature variables to X_train_rfe\n",
    "X_train_rfe = X_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a linear model, print stats summary & VIF values\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X_train_lm = sm.add_constant(X_train_rfe)\n",
    "\n",
    "lm = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "print(lm.summary())\n",
    "build_VIF(X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All  p-values are looking good. VIF values are very high. Some variables such as cylindernumber have a negative coefficient which is at odds with their individual correlation with price. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the FIRST iteration of model over RFE model by dropping *cylindernumber* since by itself it has a positive correlation with price and yet in this model it shows a negative coefficient. It seems like an unreliable variable for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train_rfe.drop([\"cylindernumber\"], axis = 1)\n",
    "\n",
    "# Build first revised fitted model\n",
    "X_train_lm = sm.add_constant(X_train_1)\n",
    "lm_1 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lm_1.summary())\n",
    "\n",
    "# Calculate the VIFs again for the new model (after dropping feature)\n",
    "build_VIF(X_train_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build SECOND iteration of model over RFE model by dropping *stroke* due to high p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train_1.drop([\"stroke\"], axis = 1)\n",
    "\n",
    "# Build the second revised fitted model\n",
    "X_train_lm = sm.add_constant(X_train_2)\n",
    "lm_2 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lm_2.summary())\n",
    "\n",
    "# Calculate the VIFs again for the new model (after dropping variable)\n",
    "build_VIF(X_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build THIRD iteration of model over RFE model by dropping *boreratio* for the same reason as *cylindernumber* (-ve coef but +ve correlation by itself with price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_3 = X_train_2.drop([\"boreratio\"], axis = 1)\n",
    "\n",
    "# Build a third fitted model\n",
    "X_train_lm = sm.add_constant(X_train_3)\n",
    "lm_3 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lm_3.summary())\n",
    "\n",
    "# Calculate the VIFs again for the new model \n",
    "build_VIF(X_train_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Build a FOURTH iteration of the model dropping *curbweight* due to high VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_4 = X_train_3.drop([\"curbweight\"], axis = 1)\n",
    "\n",
    "# Build a fourth fitted model\n",
    "X_train_lm = sm.add_constant(X_train_4)\n",
    "lm_4 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lm_4.summary())\n",
    "\n",
    "# Calculate the VIFs again for the new model \n",
    "build_VIF(X_train_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the FIFTH iteration, dropping  *porsche*  due to high p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_5 = X_train_4.drop([\"porsche\"], axis = 1)\n",
    "\n",
    "# Build a fifth fitted model\n",
    "X_train_lm = sm.add_constant(X_train_5)\n",
    "lm_5 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lm_5.summary())\n",
    "\n",
    "# Calculate the VIFs again for the new model \n",
    "build_VIF(X_train_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the SIXTH iteration, dropping  *carwidth* due to high VIF (instead of *enginesize* since it is better to  to retain that one for  interpretability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_6 = X_train_5.drop([\"carwidth\"], axis = 1)\n",
    "\n",
    "# Build a fifth fitted model\n",
    "X_train_lm = sm.add_constant(X_train_6)\n",
    "lm_6 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lm_6.summary())\n",
    "\n",
    "# Calculate the VIFs again for the new model \n",
    "build_VIF(X_train_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the SEVENTH iteration, dropping  *peugeot* due to high p-Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_7 = X_train_6.drop([\"peugeot\"], axis = 1)\n",
    "\n",
    "# Build a fifth fitted model\n",
    "X_train_lm = sm.add_constant(X_train_7)\n",
    "lm_7 = sm.OLS(y_train, X_train_lm).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(lm_7.summary())\n",
    "\n",
    "# Calculate the VIFs again for the new model \n",
    "build_VIF(X_train_7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Decent Model now with good p-Values, a moderate Adj R-squared value of 79% & low VIF values (all below 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Residual Analysis of the train data\n",
    "\n",
    "Now to check if the error terms are also normally distributed (which is a major assumption of linear regression), plot the histogram of the error terms and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lm = LinearRegression()\n",
    "lm = sm.OLS(y_train, X_train_lm).fit()\n",
    "y_train_price = lm.predict(X_train_lm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_price), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)                         # X-label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The error histogram seems to have approximate normal distribution. However, two concerns\n",
    "1. Mean is centred below zero\n",
    "2. The right tail is a bit long.\n",
    "\n",
    "No better option at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Making Predictions Using the Final Model\n",
    "\n",
    "Now that we have fitted the model and checked the normality of error terms,  \n",
    "make predictions using the final, i.e. third model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the scaling on the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply scaler() to relevant columns \n",
    "#num_vars = ['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight', 'enginesize', 'horsepower', \\\n",
    "#            'peakrpm', 'citympg', 'highwaympg', 'compressionratio','symboling']\n",
    "\n",
    "num_vars = cars_test.columns\n",
    "\n",
    "cars_test[num_vars] = scaler.fit_transform(cars_test[num_vars])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing into X_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = cars_test.pop('price')\n",
    "X_test = cars_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant variable to test dataframe\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_test dataframe \n",
    "\n",
    "cols = X_train_7.columns\n",
    "X_test = X_test[cols]\n",
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the third  model\n",
    "\n",
    "lm = sm.OLS(y_test, X_test).fit()\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Model Evaluation\n",
    "\n",
    "Plot the graph for actual versus predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test, y_pred)\n",
    "fig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize = 18)                          # X-label\n",
    "plt.ylabel('y_pred', fontsize = 16)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, We can see that the equation of our best fitted line is:\n",
    "\n",
    "$ price = 1.1  \\times  enginesize + 1.1  \\times  bmw +  rear$\n",
    "\n",
    "However, there is a bit of variance showing in the lower values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW, Evaluate an ALTERNATE model, built using RFE without further iterations.\n",
    "\n",
    "This model has a very high Adj R-Squared of 90% and good p-values.\n",
    "Only anamoly is high VIFs for some variables and -ve coef for some features which by themselves +vely correlated to price.\n",
    "\n",
    "$ price = 1.2 \\times enginesize + 0.43  \\times  carwidth + 0.35 \\times curbweight + + 0.27 \\times rear + 0.24 \\times bmw + 0.23 \\times peugeot  - 0.91  \\times cylindernumber - 0.37 \\times boreratio - 0.3 \\times stroke  - 0.12 \\times peugeot $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7A: Residual Analysis of the train data \n",
    "\n",
    "Check if the error terms are also normally distributed (which is a major assumption of linear regression), plot the histogram of the error terms and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_train, cars_test = train_test_split(cars, train_size = 0.7, test_size = 0.3, random_state = 100)\n",
    "\n",
    "#lm = LinearRegression()\n",
    "X_train_lm = X_train_rfe\n",
    "X_train_lm = sm.add_constant(X_train_rfe)\n",
    "lm = sm.OLS(y_train, X_train_lm).fit()\n",
    "y_train_price = lm.predict(X_train_lm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_price), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)                         # X-label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The error histogram seems to have approximate normal distribution and seems to be in better shape than the one evaluated for the previous model. The right tail is more gradual compared to the previous model. The Mean is still centred slightly below zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8A: Making Predictions Using the Final Model\n",
    "\n",
    "Now that we have fitted the model and checked the normality of error terms,  \n",
    "make predictions using the final, i.e. third model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the scaling on the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply scaler() to relevant columns \n",
    "#num_vars = ['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight', 'enginesize', 'horsepower', \\\n",
    "#            'peakrpm', 'citympg', 'highwaympg', 'compressionratio','symboling']\n",
    "\n",
    "num_vars = cars_test.columns\n",
    "\n",
    "cars_test[num_vars] = scaler.fit_transform(cars_test[num_vars])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing into X_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = cars_test.pop('price')\n",
    "\n",
    "X_test = cars_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant variable to test dataframe\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_test dataframe \n",
    "\n",
    "cols = X_train_1.columns\n",
    "X_test = X_test[cols]\n",
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the third  model\n",
    "\n",
    "lm = sm.OLS(y_test, X_test).fit()\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9A: Model Evaluation\n",
    "\n",
    "Plot the graph for actual versus predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test, y_pred)\n",
    "fig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize = 18)                          # X-label\n",
    "plt.ylabel('y_pred', fontsize = 16)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So, We can see that the equation of our best fitted line for this alternate model is\n",
    "\n",
    "\n",
    "$ price = 1.2 \\times enginesize + 0.43  \\times  carwidth + 0.35 \\times curbweight + + 0.27 \\times rear + 0.24 \\times bmw + 0.23 \\times peugeot  - 0.91  \\times cylindernumber - 0.37 \\times boreratio - 0.3 \\times stroke  - 0.12 \\times peugeot $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion / Intepretations :\n",
    "\n",
    "1. The final fitted y-test & y-pred graphs between the two models (X_train_7 & X_Train_RFE) are not very different.\n",
    "\n",
    "2. Since the X_train_7 models has fewer variables and easier to interpret, we shall go with that model which has the following equation\n",
    "$ price = 1.1  \\times  enginesize + 1.1  \\times  bmw +  rear$\n",
    "\n",
    "This tells us that the price of the cars is most positively affected by the following features, in that order\n",
    "    1. Engine size,\n",
    "    2. Whether it is a BMW & \n",
    "    3. Whether it has a rear engine\n",
    "    \n",
    "Interestingly, as it happens, BMW does not make rear-engine cars, which means features 2 & 3 are mutually exclusive. \n",
    "\n",
    "Additional interpretations of this:\n",
    "1. A non-BMW car will have a higher price than a BMW only if it's engine size is larger than the BMW car.\n",
    "2. A BMW car will always have the best price as long as the cars being compared are of smaller size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
